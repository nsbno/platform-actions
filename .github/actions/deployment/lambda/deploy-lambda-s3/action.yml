inputs:
  function-name:
    description: "The name of the Lambda Function"
    required: true
  lambda-s3-bucket:
    description: "The S3 Bucket to upload the Lambda package to"
    required: true
  aws-region:
    description: "The AWS Region to use for the deployment"
    required: false
    default: "eu-west-1"
  file-extension:
    description: "The file extension of the Lambda package"
    required: false
    default: "zip"

runs:
  using: composite
  steps:
    - name: Update Datadog Environment Tags if enabled
      uses: nsbno/platform-actions/.github/actions/deployment/lambda/update-datadog-tags@main
      with:
        function-name: ${{ inputs.function-name }}
        aws-region: ${{ inputs.aws-region }}

    - name: Publish Lambda Version
      id: publish
      shell: bash
      env:
        AWS_REGION: ${{ inputs.aws-region }}
      run: |
        LAMBDA_NAME="${{ inputs.function-name }}"
        # TODO: Refactor the way to find S3 bucket name. Now it is tightly coupled to Terraform Vy Provider.
        # We are missing a way to connect a service account id to an environment in the pipeline.
        S3_BUCKET="${{ inputs.lambda-s3-bucket }}"
        S3_KEY_PATH="$LAMBDA_NAME/${{ github.event.pull_request.head.sha || github.sha }}.${{ inputs.file-extension }}"
        
        NEW_LAMBDA_VERSION=$(aws lambda update-function-code --function-name "$LAMBDA_NAME" --s3-bucket "$S3_BUCKET" --s3-key "$S3_KEY_PATH" --query 'Version' --publish --output text)
        echo "new_lambda_version=$NEW_LAMBDA_VERSION" >> $GITHUB_OUTPUT

    - name: Update Lambda Alias to New Version
      shell: bash
      env:
        AWS_REGION: ${{ inputs.aws-region }}
      run: |
        aws lambda update-alias --function-name "${{ inputs.function-name }}" --name active --function-version "${{ steps.publish.outputs.new_lambda_version }}"
