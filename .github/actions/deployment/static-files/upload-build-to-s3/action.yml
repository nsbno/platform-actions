name: Upload Build to S3 with SHA

inputs:
  github-repository-name:
    description: "GitHub repository name"
    required: true
  working-directory:
    description: "Working directory within the repository"
    required: true
  s3-bucket-name:
    description: "Name of the bucket to upload static files to."
    required: true
  git-sha:
    required: true
    description: "Git SHA to use for versioning"
  s3-static-files-path:
    description: "Path in S3 bucket to upload static files to."
    required: false
    default: "static"
  cache-control-config:
    description: "Path to cache-control config file (relative to repository root)"
    required: false
    default: ".static-files-cache.yml"

runs:
  using: composite
  steps:
    # We can remove this in the future as we only use this to find the bucket name of the service account
    - name: Find S3 Service Account Bucket Name
      id: find-latest-s3-artifact
      uses: nsbno/platform-actions/.github/actions/helpers/make-aws-api-call@v2
      with:
        http-method: GET
        # using '/lambda' is a bit misleading, but it just means the version is set before Terraform runs
        endpoint: https://version-handler.vydeployment.vydev.io/v2/versions/${{inputs.github-repository-name}}/lambda?working_directory=${{inputs.working-directory}}
        continue-on-error: false

    - name: Download and unzip artifact from S3
      shell: bash
      env:
        GIT_REPO_NAME: ${{ inputs.github-repository-name }}
        WORKING_DIRECTORY: ${{ inputs.working-directory }}
        GIT_SHA: ${{ inputs.git-sha }}
      run: |
        SERVICE_BUCKET_NAME=$(echo '${{ steps.find-latest-s3-artifact.outputs.response }}' | jq -r '.bucket_name')

        # Build S3 object path
        if [ -n "$WORKING_DIRECTORY" ]; then
          S3_OBJECT_PATH="${GIT_REPO_NAME}/${WORKING_DIRECTORY}/${GIT_SHA}.zip"
        else
          S3_OBJECT_PATH="${GIT_REPO_NAME}/${GIT_SHA}.zip"
        fi

        aws s3 cp "s3://${SERVICE_BUCKET_NAME}/${S3_OBJECT_PATH}" ./build.zip
        unzip build.zip -d "./content-to-upload"

    - name: Install Python dependencies
      shell: bash
      run: |
        python3 -m pip install -q boto3 PyYAML

    - name: Upload build files to S3
      shell: bash
      id: upload
      run: |
        python3 ${{ github.action_path }}/upload.py \
          "./content-to-upload" \
          "${{ inputs.s3-bucket-name }}" \
          "${{ inputs.s3-static-files-path }}/${{ inputs.git-sha }}" \
          "${{ inputs.cache-control-config }}"
